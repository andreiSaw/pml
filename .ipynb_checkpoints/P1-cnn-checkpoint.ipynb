{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.exposure import equalize_hist\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some images from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 80\n",
    "shape =  2 * (size,)\n",
    "\n",
    "X, y = shuffle(np.load('x_train.npy'), np.load('y_train.npy'))\n",
    "\n",
    "width, height = 8, 8\n",
    "\n",
    "plt.figure(figsize=(16, 20))\n",
    "for n, (image, name) in enumerate(zip(X, y), 1):\n",
    "    if n > width * height:\n",
    "        break\n",
    "        \n",
    "    plt.subplot(height, width, n)\n",
    "    plt.title(name)\n",
    "    plt.imshow(image.reshape(shape), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define simple image preparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(img):\n",
    "    img = img.reshape(shape)\n",
    "    img = equalize_hist(img)\n",
    "    img = gaussian(img, sigma=1)\n",
    "    img - img.mean()\n",
    "    \n",
    "    return img.flatten()\n",
    "    \n",
    "def transform(X):\n",
    "    height, width = X.shape\n",
    "    for i in range(height):\n",
    "        X[i] = prepare(X[i]) \n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pca decomposition to reduce the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 8, 8\n",
    "\n",
    "plt.figure(figsize=(16, 20))\n",
    "for n, component in enumerate(pca.components_, 1):\n",
    "    if n > width * height:\n",
    "        break\n",
    "        \n",
    "    plt.subplot(height, width, n)\n",
    "    plt.imshow(component.reshape(shape), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D \n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "a_train, a_test, b_train, b_test = train_test_split(pca.transform(X_train), y_train, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(10,20,6)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, (2, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(256, (2, 2), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network=createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "my_network.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['acc'])\n",
    "print('The crash is right after this')\n",
    "history = my_network.fit(trainX, trainY, batch_size=batch_size, epochs=epochs, validation_data=(testX, testY))\n",
    "my_network.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "weight_options = ['uniform', 'distance']\n",
    "\n",
    "param_grid = dict(n_neighbors=[1,2,3], weights=weight_options, p=[1, 1.5, 2] )\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the end we use the nearest neighbors to classify faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "data_test = pd.read_csv(data_path+'/data_test.csv.gz')\n",
    "\n",
    "# Create images\n",
    "images_test = create_images(data_test, \n",
    "                            n_theta_bins=10, \n",
    "                            n_phi_bins=20, \n",
    "                            n_time_bins=6)\n",
    "\n",
    "# Scale images\n",
    "X_test = images_test / 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= my_network.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as out:\n",
    "    print('Id,Name', file=out)\n",
    "    for pair in enumerate(prediction, 1):\n",
    "        print('%i,%s' % pair, file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
